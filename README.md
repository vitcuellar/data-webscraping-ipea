# Webscraping: IPEA Data

[![Leia em Ingl√™s](https://img.shields.io/badge/Ler%20em-Ingl√™s-blue)](README_eng.md)

## üíº Sobre o Projeto

Este projeto demonstra minhas habilidades em web scraping, an√°lise de dados e visualiza√ß√£o utilizando Python.

O principal objetivo √© analisar a cota√ß√£o hist√≥rica do d√≥lar americano (USD) em rela√ß√£o ao real brasileiro (BRL), investigando como eventos globais importantes influenciaram suas varia√ß√µes ao longo dos anos. Os dados foram coletados por meio de t√©cnicas de web scraping e processados com bibliotecas Python como BeautifulSoup (bs4), Pandas e Matplotlib.

Mais do que a execu√ß√£o t√©cnica, este projeto simula o desenvolvimento de uma an√°lise financeira replic√°vel, que poderia ser incorporada a um relat√≥rio de intelig√™ncia de mercado para uma empresa do setor financeiro.

O objetivo √© oferecer insights valiosos, ao mesmo tempo em que demonstra como o Python pode ser aplicado na an√°lise de dados financeiros do mundo real.


## üîé Onde encontrar?

### code_webscraping:
Aqui tem o c√≥digo em Python com a extra√ß√£o dos dados do website IPEA Data. Desde o momento de extra√ß√£o at√© o tratamento dos dados e armazenamento deles em vari√°veis que ser√£o usadas nas an√°lises.

### code_analysis_dollar_taxes

Nessa pasta cont√©m o c√≥digo para as 3 an√°lises realizadas + arquivo README.md com an√°lise escrita[code_analysis_dollar_taxes/analise.md]em vers√£o em ingl√™s e portugu√™s.


## üë©üèª‚Äçüíª Resumo - Documenta√ß√£o T√©cnica

### 1) Requisi√ß√£o HTTP

Estamos lidando com um _website_, portanto, temos que tratar isso como uma requisi√ß√£o. Logo, os primeiros passos foi a busca da URL e defini√ß√£o da fun√ß√£o de requisi√ß√£o.

Al√©m disso, tamb√©m implementamos uma valida√ß√£o para verificar se a resposta foi bem-sucedida (status code 200).

### 2) Parsing HTML

Para realizar o parsing, que nada mais √© do que uma leitura na p√°gina, utilizamos o BeautifulSoup para fazer isso. Algo muito importante aqui √© prover informa√ß√µes para que a tabela ou dados que necessitem ser localizados, assim sejam. 

Por conta disso, implementamos a localiza√ß√£o padr√£o de tabela, considerando ID 'grd_DXMainTable' (padr√£o em p√°ginas ASP.NET com DevExpress).
Aqui se essa localiza√ß√£o n√£o for bem sucedida, garantimos que a tabela ser√° encontrada com uma outra busca:  class="dxgvTable_Moderno".


### 3) Identifica√ß√£o do Cabe√ßalho

Uma vez que os dados da tabela foram encontrados, agora √© tentar localizar os cabe√ßalhos e isso fizemos usando a classe 'dxgvHeader_Moderno'.
Se n√£o encontrar, aplica uma l√≥gica alternativa para inferir o cabe√ßalho a partir das primeiras linhas da tabela.

Por se tratar de um website relativamente simples, como _fallback_ final, definimos manualmente os **nomes das colunas: ['Data', 'Taxa de c√¢mbio - R$ / US$ - comercial - compra - m√©dia'].**

### 4) Extra√ß√£o das Linhas de Dados

Assim que o cabe√ßalho foi encontrado, vamos procurar por linhas com a classe 'dxgvDataRow_Moderno'.
Se n√£o houver, tenta identificar linhas de dados com base na quantidade de colunas e na aus√™ncia de elementos.

Logo em seguida, foi necess√°rio implementar uma regra que garantisse que o n√∫mero de colunas das linhas de dados seja igual ao n√∫mero de colunas do cabe√ßalho.

### 5) Cria√ß√£o do DataFrame

Usando pandas, constru√≠mos um _pandas.DataFrame_ com os dados extra√≠dos e os nomes de colunas identificados. Tamb√©m fizemos algumas altera√ß√µes nos nomes das colunas para que fosse mais f√°cil trabalhar na parte da an√°lise.

### 6) Tratamento de Exce√ß√µes

Em todo o c√≥digo voc√™ vai ver que lidamos com os poss√≠veis erros por meio de exce√ß√µes e prints de logs de erro.
